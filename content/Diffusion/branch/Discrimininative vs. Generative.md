---
date: 2025-07-09
created: 2025-07-09
modified: 2025-07-09
---

왜 **“Generative” 모델**은 $p_\theta(x)$를 통째로 배워야할까?

- **분류할 때**는
    - **“이 입력 $x$가 정답 $y$ 중 어디에 가까운지만”** 알면 되지만,
- **생성할 때**는
    - **“$x$가 어떻게 다양하게 나타날 수 있는지 전부”** 알아야
    - “$x$ 하나”를 새로 만들어 낼 수 있다. 

## 쉽게 예를 들어 설명하면, 
### Discriminative Model
> 감별사 (e.g. Regression, Classification, …)

문제: **“이 그림이 고양이야, 개야?”** <br><br>
고양이와 개를 **구분**하는 기준(경계선)만 배우면 된다.<br>
→ $p(y\mid x)$ 만 배우면 충분하다!

### Generative Model
> 화가

문제: **“새로운 고양이 그림을 그려 줘”**<br><br>
<u>알아야 할 것들</u>: 
1. 고양이가 **어떤 모양**, **어떤 색채**를 가질 수 있는지
2. 고양이가 자연스럽게 보이도록 **모든 디테일**(털, 눈, 그림자 등)  <br>
전 과정을 **처음부터 끝까지** 알아야 한다. 

→ $p(x)$, <font color="#e36c09">즉 <b>“어떤 픽셀이 나오고 어떤 색이 섞일 확률”</b> 전체 분포를 모델링해야 새로운 샘플을 만들 수 있다. </font>
